{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1562/1562 [==============================] - 27s 16ms/step - loss: 2.0068 - accuracy: 0.2641 - val_loss: 1.8454 - val_accuracy: 0.3242\n",
      "Epoch 2/10\n",
      "1562/1562 [==============================] - 25s 16ms/step - loss: 1.9037 - accuracy: 0.3083 - val_loss: 1.7922 - val_accuracy: 0.3604\n",
      "Epoch 3/10\n",
      "1562/1562 [==============================] - 26s 17ms/step - loss: 1.8527 - accuracy: 0.3296 - val_loss: 1.7358 - val_accuracy: 0.3744\n",
      "Epoch 4/10\n",
      "1562/1562 [==============================] - 26s 17ms/step - loss: 1.8264 - accuracy: 0.3405 - val_loss: 1.6758 - val_accuracy: 0.4042\n",
      "Epoch 5/10\n",
      "1562/1562 [==============================] - 26s 17ms/step - loss: 1.8018 - accuracy: 0.3509 - val_loss: 1.6588 - val_accuracy: 0.4050\n",
      "Epoch 6/10\n",
      "1562/1562 [==============================] - 27s 17ms/step - loss: 1.7859 - accuracy: 0.3554 - val_loss: 1.6522 - val_accuracy: 0.4038\n",
      "Epoch 7/10\n",
      "1562/1562 [==============================] - 25s 16ms/step - loss: 1.7758 - accuracy: 0.3606 - val_loss: 1.6299 - val_accuracy: 0.4229\n",
      "Epoch 8/10\n",
      "1562/1562 [==============================] - 27s 17ms/step - loss: 1.7584 - accuracy: 0.3637 - val_loss: 1.6274 - val_accuracy: 0.4097\n",
      "Epoch 9/10\n",
      "1562/1562 [==============================] - 26s 16ms/step - loss: 1.7510 - accuracy: 0.3673 - val_loss: 1.6319 - val_accuracy: 0.4078\n",
      "Epoch 10/10\n",
      "1562/1562 [==============================] - 26s 17ms/step - loss: 1.7440 - accuracy: 0.3701 - val_loss: 1.6243 - val_accuracy: 0.4167\n",
      "313/313 - 1s - loss: 1.6243 - accuracy: 0.4167 - 609ms/epoch - 2ms/step\n",
      "\n",
      "Test accuracy: 0.41670000553131104\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 3)),  \n",
    "    Dense(128, activation='relu'),     \n",
    "    Dense(64, activation='relu'),      \n",
    "    Dense(10, activation='softmax')    \n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_datagen.flow(x_train, y_train, batch_size=32),\n",
    "          steps_per_epoch=len(x_train) / 32,\n",
    "          epochs=10,\n",
    "          validation_data=test_datagen.flow(x_test, y_test, batch_size=32),\n",
    "          validation_steps=len(x_test) / 32)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize images\n",
    "])\n",
    "\n",
    "svhn_train = datasets.SVHN(root='./data', split='train', download=True, transform=transform)\n",
    "svhn_test = datasets.SVHN(root='./data', split='test', download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(svhn_train, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(svhn_test, batch_size=32, shuffle=False)\n",
    "\n",
    "models_to_compare = {\n",
    "    \"AlexNet\": models.alexnet(pretrained=True),\n",
    "    \"VGG16\": models.vgg16(pretrained=True),\n",
    "    \"ResNet18\": models.resnet18(pretrained=True),\n",
    "    \"ResNet50\": models.resnet50(pretrained=True),\n",
    "    \"ResNet101\": models.resnet101(pretrained=True)\n",
    "}\n",
    "\n",
    "def fine_tune_model(model, num_classes):\n",
    "    if isinstance(model, models.ResNet):\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    elif isinstance(model, models.VGG):\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "    elif isinstance(model, models.AlexNet):\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Model not supported for fine-tuning\")\n",
    "\n",
    "    return model\n",
    "\n",
    "for model_name, model in models_to_compare.items():\n",
    "    model = fine_tune_model(model, num_classes=10)\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"{model_name} - Accuracy on test set: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
